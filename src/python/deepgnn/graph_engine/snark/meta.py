# Copyright (c) Microsoft Corporation.
# Licensed under the MIT License.

"""Meta module provides functionality to work with binary graph files."""
import enum
import os
import tempfile
from ctypes import c_char_p
from deepgnn.graph_engine.snark._lib import _get_c_lib
import platform

"""Version of binary files produced by converters to communicate breaking changes requiring regeneration of binary files."""
BINARY_DATA_VERSION = "v1"


# Use custom separators in case we want to download data from remote filesystems.
def _get_meta_path(path: str, sep=os.path.sep) -> str:
    return sep.join([path, "meta.txt"])


def _get_node_map_path(
    path: str, partition: int, iteration: int, sep=os.path.sep
) -> str:
    suffix = "*" if iteration < 0 else str(iteration)
    return sep.join([path, "node_{}_{}.map".format(partition, suffix)])


class _Element(enum.Enum):
    NODE = "node"
    EDGE = "edge"


def _get_element_index_path(
    element: _Element, path: str, partition: int, iteration: int, sep=os.path.sep
) -> str:
    suffix = "*" if iteration < 0 else str(iteration)
    return sep.join([path, "{}_{}_{}.index".format(element.value, partition, suffix)])


def _get_element_features_index_path(
    element: _Element, path: str, partition: int, iteration: int, sep=os.path.sep
) -> str:
    suffix = "*" if iteration < 0 else str(iteration)
    return sep.join(
        [path, "{}_features_{}_{}.index".format(element.value, partition, suffix)]
    )


def _get_element_sparse_features_index_path(
    element: _Element, path: str, partition: int, iteration: int, sep=os.path.sep
) -> str:
    suffix = "*" if iteration < 0 else str(iteration)
    return sep.join(
        [
            path,
            "{}_sparse_features_{}_{}.index".format(element.value, partition, suffix),
        ]
    )


def _get_element_features_data_path(
    element: _Element, path: str, partition: int, iteration: int, sep=os.path.sep
) -> str:
    suffix = "*" if iteration < 0 else str(iteration)
    return sep.join(
        [path, "{}_features_{}_{}.data".format(element.value, partition, suffix)]
    )


def _get_element_alias_path(
    element: _Element, path: str, tp: int, partition: int, sep=os.path.sep
) -> str:
    type_expr = "*" if tp < 0 else str(tp)
    return sep.join(
        [path, "{}_{}_{}.alias".format(element.value, type_expr, partition)]
    )


def _get_neighbors_index_path(
    path: str, partition: int, iteration: int, sep=os.path.sep
) -> str:
    suffix = "*" if iteration < 0 else str(iteration)
    return sep.join([path, "neighbors_{}_{}.index".format(partition, suffix)])


def _set_hadoop_classpath(config_dir):
    if platform.system() != "Linux":
        raise ValueError("HDFS only supported for linux!")
    if "CLASSPATH" in os.environ:
        return
    if config_dir.endswith(".xml"):
        config_dir = os.path.dirname(config_dir)
    hadoop_home = os.environ["HADOOP_HOME"]
    paths = set()
    for root, dirs, filenames in os.walk(hadoop_home):
        if any([filename.endswith(".jar") for filename in filenames]):
            if len(dirs):
                for dir in dirs:
                    paths.add(f"{root}/{dir}/*")
            else:
                paths.add(f"{root}/*")
    os.environ["CLASSPATH"] = f"{config_dir}:{':'.join(paths)}"


class Meta:
    """General information about the graph: number of node, edges, types, partititons, etc."""

    def __init__(self, path: str, config_path: str = ""):
        """
        Parse a metadata file generated by a converter.

        Args:
            path (str): location of graph binary files.
        """
        if (
            path.startswith("hdfs://")
            or path.startswith("adl://")
            or path.startswith("file:///")
        ):
            _set_hadoop_classpath(config_path)

            class _ErrCallback:  # Copied from client.py
                def __init__(self, method: str):
                    self.method = method

                # We have to use mypy ignore, to reuse this callable object across
                # all C function call because they have different signatures.
                def __call__(self, result, func, arguments):
                    if result != 0:
                        raise Exception(f"Failed to {self.method}")

            lib = _get_c_lib()
            lib.HDFSMoveMeta.errcheck = _ErrCallback("hdfs move meta")  # type: ignore

            hdfs_path = path
            temp_dir = tempfile.TemporaryDirectory()
            path = temp_dir.name
            lib.HDFSMoveMeta(
                c_char_p(bytes(_get_meta_path(hdfs_path), "utf-8")),
                c_char_p(bytes(_get_meta_path(path), "utf-8")),
                c_char_p(bytes(config_path, "utf-8")),
            )

        meta = open(_get_meta_path(path), "r")  # type: ignore

        self.version = str(meta.readline().strip())
        self.node_count = int(meta.readline())
        self.edge_count = int(meta.readline())
        self.node_type_count = int(meta.readline())
        self.edge_type_count = int(meta.readline())
        self._node_feature_count = int(meta.readline())
        self._edge_feature_count = int(meta.readline())
        self._partition_count = int(meta.readline())
        self._node_weights = [float(0)] * self.node_type_count
        self._edge_weights = [float(0)] * self.edge_type_count
        for _ in range(self._partition_count):
            meta.readline()  # Partition id
            for i in range(self.node_type_count):
                self._node_weights[i] += float(meta.readline())
            for i in range(self.edge_type_count):
                self._edge_weights[i] += float(meta.readline())
        self.node_count_per_type = []
        self.edge_count_per_type = []

        for _ in range(self.node_type_count):
            self.node_count_per_type.append(int(meta.readline()))
        for _ in range(self.edge_type_count):
            self.edge_count_per_type.append(int(meta.readline()))

        meta.close()
