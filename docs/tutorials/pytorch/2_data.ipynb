{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Caveman Dataset with GAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "random.seed(0)\n",
    "num_clusters = 5\n",
    "num_nodes_in_cluster = 10\n",
    "g = nx.connected_caveman_graph(num_clusters, num_nodes_in_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "working_dir = \"/tmp/caveman\"\n",
    "try:\n",
    "    os.mkdir(working_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "test_pct = .2  # Percent of nodes in test set\n",
    "nodes = []\n",
    "data = \"\"\n",
    "for node_id in g:\n",
    "    cluster_id = float(node_id // num_nodes_in_cluster)\n",
    "    normalized_cluster = cluster_id / num_clusters - 0.4\n",
    "    node = {\n",
    "        \"node_id\": node_id,  # int\n",
    "        \"node_type\": 1 if random.random() < test_pct else 0,  # int\n",
    "        \"node_weight\": 1.,  # float\n",
    "        \"uint64_feature\": None,  # None or {\"feature id\": [\"int\", \"...\"], \"...\": \"...\"},\n",
    "        \"float_feature\": {\n",
    "            \"0\": [\n",
    "                0.02 * random.uniform(0, 1) + 2.5 * normalized_cluster - 0.01,\n",
    "                random.uniform(0, 1),\n",
    "            ],\n",
    "            \"1\": [cluster_id],\n",
    "        },  #  {\"feature id\": [\"float\", \"...\"], \"...\": \"...\"},\n",
    "        \"binary_feature\": None,  # {\"feature id\": \"string\", \"...\": \"...\"},\n",
    "        \"edge\": [\n",
    "            {\n",
    "                \"src_id\": node_id,  # int\n",
    "                \"dst_id\": neighbor_id,  # int\n",
    "                \"edge_type\": 0,  # int\n",
    "                \"weight\": 1.0,  # float\n",
    "                #     \"uint64_feature\": {\"feature id\": [\"int\", \"...\"], \"...\": [\"int\", \"...\"]},\n",
    "                #     \"float_feature\": {\"feature id\": [\"float\", \"...\"], \"...\": [\"float\", \"...\"]},\n",
    "                #     \"binary_feature\": {\"feature id\": \"string\", \"...\": \"...\"}\n",
    "            }\n",
    "            for neighbor_id in nx.neighbors(g, node_id)\n",
    "        ],\n",
    "        \"neighbor\": {\n",
    "            \"0\": dict(\n",
    "                [\n",
    "                    (str(neighbor_id), 1.0)\n",
    "                    for neighbor_id in nx.neighbors(g, node_id)\n",
    "                ]\n",
    "            )\n",
    "        },  # {\"edge type\": {\"neighbor id\": \"weight\", \"...\": \"...\"}, \"...\": \"...\"}\n",
    "    }\n",
    "    data += json.dumps(node) + \"\\n\"\n",
    "    nodes.append(node)\n",
    "\n",
    "data_filename = f\"{working_dir}/graph.json\"\n",
    "with open(data_filename, \"w+\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepgnn.graph_engine.snark.convert as convert\n",
    "from deepgnn.graph_engine.snark.decoders import JsonDecoder\n",
    "partitions = 1\n",
    "convert.MultiWorkersConverter(\n",
    "    graph_path=data_filename,\n",
    "    partition_count=partitions,\n",
    "    output_dir=working_dir,\n",
    "    decoder_class=JsonDecoder,\n",
    ").convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from deepgnn.pytorch.common import Accuracy\n",
    "from deepgnn.pytorch.modeling.base_model import BaseModel\n",
    "from deepgnn.pytorch.nn.gat_conv import GATConv\n",
    "\n",
    "from deepgnn.graph_engine import Graph, FeatureType, graph_ops\n",
    "\n",
    "from deepgnn import str2list_int\n",
    "from deepgnn.pytorch.common.utils import set_seed\n",
    "from deepgnn.pytorch.common.dataset import TorchDeepGNNDataset\n",
    "from deepgnn.pytorch.modeling import BaseModel\n",
    "from deepgnn.pytorch.training import run_dist\n",
    "from deepgnn.graph_engine import GENodeSampler, FileNodeSampler, GraphEngineBackend  # Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GATQueryParameter:\n",
    "    neighbor_edge_types: np.array\n",
    "    feature_idx: int\n",
    "    feature_dim: int\n",
    "    label_idx: int\n",
    "    label_dim: int\n",
    "    feature_type: FeatureType = FeatureType.FLOAT\n",
    "    label_type: FeatureType = FeatureType.FLOAT\n",
    "    num_hops: int = 2\n",
    "\n",
    "class GATQuery:\n",
    "    def __init__(self, p: GATQueryParameter):\n",
    "        self.p = p\n",
    "        self.label_meta = np.array([[p.label_idx, p.label_dim]], np.int32)\n",
    "        self.feat_meta = np.array([[p.feature_idx, p.feature_dim]], np.int32)\n",
    "\n",
    "    def query_training(self, graph: Graph, inputs):\n",
    "        nodes, edges, src_idx = graph_ops.sub_graph(\n",
    "            graph,\n",
    "            inputs,\n",
    "            edge_types=self.p.neighbor_edge_types,\n",
    "            num_hops=self.p.num_hops,\n",
    "            self_loop=True,\n",
    "            undirected=True,\n",
    "            return_edges=True,\n",
    "        )\n",
    "        input_mask = np.zeros(nodes.size, np.bool)\n",
    "        input_mask[src_idx] = True\n",
    "\n",
    "        feat = graph.node_features(nodes, self.feat_meta, self.p.feature_type)\n",
    "        label = graph.node_features(nodes, self.label_meta, self.p.label_type)\n",
    "        label = label.astype(np.int32)\n",
    "        edges_value = np.ones(edges.shape[0], np.float32)\n",
    "        edges = np.transpose(edges)\n",
    "        adj_shape = np.array([nodes.size, nodes.size], np.int64)\n",
    "\n",
    "        graph_tensor = (nodes, feat, input_mask, label, edges, edges_value, adj_shape)\n",
    "        return graph_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        head_num: List = [8, 1],\n",
    "        hidden_dim: int = 8,\n",
    "        num_classes: int = -1,\n",
    "        ffd_drop: float = 0.0,\n",
    "        attn_drop: float = 0.0,\n",
    "        q_param: GATQueryParameter = None,\n",
    "    ):\n",
    "        self.q = GATQuery(q_param)\n",
    "        super().__init__(FeatureType.FLOAT, 0, 0, None)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.out_dim = num_classes\n",
    "\n",
    "        self.input_layer = GATConv(\n",
    "            in_dim=in_dim,\n",
    "            attn_heads=head_num[0],\n",
    "            out_dim=hidden_dim,\n",
    "            act=F.elu,\n",
    "            in_drop=ffd_drop,\n",
    "            coef_drop=attn_drop,\n",
    "            attn_aggregate=\"concat\",\n",
    "        )\n",
    "        layer0_output_dim = head_num[0] * hidden_dim\n",
    "        assert len(head_num) == 2\n",
    "        self.out_layer = GATConv(\n",
    "            in_dim=layer0_output_dim,\n",
    "            attn_heads=head_num[1],\n",
    "            out_dim=self.out_dim,\n",
    "            act=None,\n",
    "            in_drop=ffd_drop,\n",
    "            coef_drop=attn_drop,\n",
    "            attn_aggregate=\"average\",\n",
    "        )\n",
    "\n",
    "        self.metric = Accuracy()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # fmt: off\n",
    "        nodes, feat, mask, labels, edges, edges_value, adj_shape = inputs\n",
    "        nodes = torch.squeeze(nodes)                # [N], N: num of nodes in subgraph\n",
    "        feat = torch.squeeze(feat)                  # [N, F]\n",
    "        mask = torch.squeeze(mask)                  # [N]\n",
    "        labels = torch.squeeze(labels)              # [N]\n",
    "        edges = torch.squeeze(edges)                # [X, 2], X: num of edges in subgraph\n",
    "        edges_value = torch.squeeze(edges_value)    # [X]\n",
    "        adj_shape = torch.squeeze(adj_shape)        # [2]\n",
    "        # fmt: on\n",
    "\n",
    "        sp_adj = torch.sparse_coo_tensor(edges, edges_value, adj_shape.tolist())\n",
    "        h_1 = self.input_layer(feat, sp_adj)\n",
    "        scores = self.out_layer(h_1, sp_adj)\n",
    "\n",
    "        labels = labels.type(torch.int64)\n",
    "        labels = labels[mask]  # [batch_size]\n",
    "        scores = scores[mask]  # [batch_size]\n",
    "        pred = scores.argmax(dim=1)\n",
    "        loss = self.xent(scores, labels)\n",
    "        return loss, pred, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(args: argparse.Namespace):\n",
    "    if args.seed:\n",
    "        set_seed(args.seed)\n",
    "\n",
    "    p = GATQueryParameter(\n",
    "        neighbor_edge_types=np.array([args.neighbor_edge_types], np.int32),\n",
    "        feature_idx=args.feature_idx,\n",
    "        feature_dim=args.feature_dim,\n",
    "        label_idx=args.label_idx,\n",
    "        label_dim=args.label_dim,\n",
    "    )\n",
    "\n",
    "    return GAT(\n",
    "        in_dim=args.feature_dim,\n",
    "        head_num=args.head_num,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        num_classes=args.num_classes,\n",
    "        ffd_drop=args.ffd_drop,\n",
    "        attn_drop=args.attn_drop,\n",
    "        q_param=p,\n",
    "    )\n",
    "\n",
    "def create_optimizer(args: argparse.Namespace, model: BaseModel, world_size: int):\n",
    "    return torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=args.learning_rate * world_size,\n",
    "        weight_decay=0.0005,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_args(parser):\n",
    "    parser.add_argument(\"--head_num\", type=str2list_int, default=\"8,1\", help=\"the number of attention headers.\")\n",
    "    parser.add_argument(\"--hidden_dim\", type=int, default=8, help=\"hidden layer dimension.\")\n",
    "    parser.add_argument(\"--num_classes\", type=int, default=-1, help=\"number of classes for category\")\n",
    "    parser.add_argument(\"--ffd_drop\", type=float, default=0.0, help=\"feature dropout rate.\")\n",
    "    parser.add_argument(\"--attn_drop\", type=float, default=0.0, help=\"attention layer dropout rate.\")\n",
    "    parser.add_argument(\"--l2_coef\", type=float, default=0.0005, help=\"l2 loss\")\n",
    "    parser.add_argument(\"--neighbor_edge_types\", type=str2list_int, default=\"0\", help=\"Graph Edge for attention encoder.\",)\n",
    "    parser.add_argument(\"--eval_file\", default=\"\", type=str, help=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(\n",
    "    args: argparse.Namespace,\n",
    "    model: BaseModel,\n",
    "    rank: int = 0,\n",
    "    world_size: int = 1,\n",
    "    backend: GraphEngineBackend = None,\n",
    "):\n",
    "    return TorchDeepGNNDataset(\n",
    "        sampler_class=GENodeSampler,  # FileNodeSampler,\n",
    "        node_types=np.array([0]),  # None\n",
    "        backend=backend,\n",
    "        query_fn=model.q.query_training,\n",
    "        prefetch_queue_size=2,\n",
    "        prefetch_worker_size=2,\n",
    "        sample_files=args.sample_file,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        worker_index=rank,\n",
    "        num_workers=world_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for .py file runs\n",
    "try:\n",
    "    init_args_base\n",
    "except NameError:\n",
    "    init_args_base = init_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for .py file runs\n",
    "MODEL_DIR = f\"tmp/gat_{np.random.randint(9999999)}\"\n",
    "arg_list = [\n",
    "    \"--data_dir\", \"/tmp/caveman\",\n",
    "    \"--mode\", \"train\",\n",
    "    \"--trainer\", \"base\",\n",
    "    \"--backend\", \"snark\",\n",
    "    \"--graph_type\", \"local\",\n",
    "    \"--converter\", \"skip\",\n",
    "    \"--node_type\", \"0\",\n",
    "    \"--feature_idx\", \"0\",\n",
    "    \"--feature_dim\", \"2\",\n",
    "    \"--label_idx\", \"1\",\n",
    "    \"--label_dim\", \"1\",\n",
    "    \"--num_classes\", str(num_clusters),\n",
    "    \"--batch_size\", \"10\",\n",
    "    \"--learning_rate\", \".005\",\n",
    "    \"--num_epochs\", \"10\",\n",
    "    \"--log_by_steps\", \"6\",\n",
    "    \"--use_per_step_metrics\",\n",
    "    \"--model_dir\", MODEL_DIR,\n",
    "    \"--metric_dir\", MODEL_DIR,\n",
    "    \"--save_path\", MODEL_DIR,\n",
    "]\n",
    "\n",
    "def init_args_wrap(init_args_base):\n",
    "    def init_args_new(parser):\n",
    "        init_args_base(parser)\n",
    "        parse_args = parser.parse_args\n",
    "        parser.parse_args = lambda: parse_args(arg_list)\n",
    "    return init_args_new\n",
    "\n",
    "init_args = init_args_wrap(init_args_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dist(\n",
    "    init_model_fn=create_model,\n",
    "    init_dataset_fn=create_dataset,\n",
    "    init_optimizer_fn=create_optimizer,\n",
    "    init_args_fn=init_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for .py file runs\n",
    "arg_list = [\n",
    "    \"--data_dir\", \"/tmp/caveman\",\n",
    "    \"--mode\", \"evaluate\",\n",
    "    \"--trainer\", \"base\",\n",
    "    \"--backend\", \"snark\",\n",
    "    \"--graph_type\", \"local\",\n",
    "    \"--converter\", \"skip\",\n",
    "    \"--node_type\", \"0\",\n",
    "    \"--feature_idx\", \"0\",\n",
    "    \"--feature_dim\", \"2\",\n",
    "    \"--label_idx\", \"1\",\n",
    "    \"--label_dim\", \"1\",\n",
    "    \"--num_classes\", str(num_clusters),\n",
    "    \"--batch_size\", \"10\",\n",
    "    \"--learning_rate\", \".0\",\n",
    "    \"--num_epochs\", \"10\",\n",
    "    \"--log_by_steps\", \"6\",\n",
    "    \"--use_per_step_metrics\",\n",
    "    \"--model_dir\", MODEL_DIR,\n",
    "    \"--metric_dir\", MODEL_DIR,\n",
    "    \"--save_path\", MODEL_DIR,\n",
    "]\n",
    "\n",
    "def init_args_wrap(init_args_base):\n",
    "    def init_args_new(parser):\n",
    "        init_args_base(parser)\n",
    "        parse_args = parser.parse_args\n",
    "        parser.parse_args = lambda: parse_args(arg_list)\n",
    "    return init_args_new\n",
    "\n",
    "init_args = init_args_wrap(init_args_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dist(\n",
    "    init_model_fn=create_model,\n",
    "    init_dataset_fn=create_dataset,\n",
    "    init_optimizer_fn=create_optimizer,\n",
    "    init_args_fn=init_args,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
