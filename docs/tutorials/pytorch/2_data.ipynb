{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Caveman Dataset with GAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "random.seed(0)\n",
    "num_clusters = 5\n",
    "num_nodes_in_cluster = 10\n",
    "g = nx.connected_caveman_graph(num_clusters, num_nodes_in_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "working_dir = \"/tmp/caveman\"\n",
    "try:\n",
    "    os.mkdir(working_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "test_pct = .2  # Percent of nodes in test set\n",
    "nodes = []\n",
    "data = \"\"\n",
    "for node_id in g:\n",
    "    cluster_id = float(node_id // num_nodes_in_cluster)\n",
    "    normalized_cluster = cluster_id / num_clusters - 0.4\n",
    "    node = {\n",
    "        \"node_id\": node_id,  # int\n",
    "        \"node_type\": 1 if random.random() < test_pct else 0,  # int\n",
    "        \"node_weight\": 1.,  # float\n",
    "        \"uint64_feature\": None,  # None or {\"feature id\": [\"int\", \"...\"], \"...\": \"...\"},\n",
    "        \"float_feature\": {\n",
    "            \"0\": [\n",
    "                0.02 * random.uniform(0, 1) + 2.5 * normalized_cluster - 0.01,\n",
    "                random.uniform(0, 1),\n",
    "            ],\n",
    "            \"1\": [cluster_id],\n",
    "        },  #  {\"feature id\": [\"float\", \"...\"], \"...\": \"...\"},\n",
    "        \"binary_feature\": None,  # {\"feature id\": \"string\", \"...\": \"...\"},\n",
    "        \"edge\": [\n",
    "            {\n",
    "                \"src_id\": node_id,  # int\n",
    "                \"dst_id\": neighbor_id,  # int\n",
    "                \"edge_type\": 0,  # int\n",
    "                \"weight\": 1.0,  # float\n",
    "                #     \"uint64_feature\": {\"feature id\": [\"int\", \"...\"], \"...\": [\"int\", \"...\"]},\n",
    "                #     \"float_feature\": {\"feature id\": [\"float\", \"...\"], \"...\": [\"float\", \"...\"]},\n",
    "                #     \"binary_feature\": {\"feature id\": \"string\", \"...\": \"...\"}\n",
    "            }\n",
    "            for neighbor_id in nx.neighbors(g, node_id)\n",
    "        ],\n",
    "        \"neighbor\": {\n",
    "            \"0\": dict(\n",
    "                [\n",
    "                    (str(neighbor_id), 1.0)\n",
    "                    for neighbor_id in nx.neighbors(g, node_id)\n",
    "                ]\n",
    "            )\n",
    "        },  # {\"edge type\": {\"neighbor id\": \"weight\", \"...\": \"...\"}, \"...\": \"...\"}\n",
    "    }\n",
    "    data += json.dumps(node) + \"\\n\"\n",
    "    nodes.append(node)\n",
    "\n",
    "data_filename = f\"{working_dir}/graph.json\"\n",
    "with open(data_filename, \"w+\") as f:\n",
    "    f.write(data)\n",
    "\n",
    "meta = '{\"node_type_num\": 2, \\\n",
    "            \"node_float_feature_num\": 2, \\\n",
    "            \"node_binary_feature_num\": 0, \\\n",
    "            \"node_uint64_feature_num\": 0, \\\n",
    "            \"edge_type_num\": 1, \\\n",
    "            \"edge_float_feature_num\": 0, \\\n",
    "            \"edge_binary_feature_num\": 0, \\\n",
    "            \"edge_uint64_feature_num\": 0}'\n",
    "\n",
    "meta_filename = f\"{working_dir}/meta.json\"\n",
    "with open(meta_filename, \"w+\") as f:\n",
    "    f.write(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-02-15 09:57:44,992] {convert.py:200} INFO - worker 0 try to generate partition: 0 - 1\n",
      "[2022-02-15 09:57:44,994] {_adl_reader.py:123} INFO - [1,0] Input files: ['/tmp/caveman/graph.json']\n"
     ]
    }
   ],
   "source": [
    "import deepgnn.graph_engine.snark.convert as convert\n",
    "from deepgnn.graph_engine.snark.decoders import JsonDecoder\n",
    "partitions = 1\n",
    "convert.MultiWorkersConverter(\n",
    "    graph_path=data_filename,\n",
    "    meta_path=meta_filename,\n",
    "    partition_count=partitions,\n",
    "    output_dir=working_dir,\n",
    "    decoder_class=JsonDecoder,\n",
    ").convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from deepgnn.pytorch.common import Accuracy\n",
    "from deepgnn.pytorch.modeling.base_model import BaseModel\n",
    "from deepgnn.pytorch.nn.gat_conv import GATConv\n",
    "\n",
    "from deepgnn.graph_engine import Graph, FeatureType, graph_ops\n",
    "\n",
    "from deepgnn import str2list_int\n",
    "from deepgnn.pytorch.common.utils import set_seed\n",
    "from deepgnn.pytorch.common.dataset import TorchDeepGNNDataset\n",
    "from deepgnn.pytorch.modeling import BaseModel\n",
    "from deepgnn.pytorch.training import run_dist\n",
    "from deepgnn.graph_engine import GENodeSampler, FileNodeSampler, GraphEngineBackend  # Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GATQueryParameter:\n",
    "    neighbor_edge_types: np.array\n",
    "    feature_idx: int\n",
    "    feature_dim: int\n",
    "    label_idx: int\n",
    "    label_dim: int\n",
    "    feature_type: FeatureType = FeatureType.FLOAT\n",
    "    label_type: FeatureType = FeatureType.FLOAT\n",
    "    num_hops: int = 2\n",
    "\n",
    "class GATQuery:\n",
    "    def __init__(self, p: GATQueryParameter):\n",
    "        self.p = p\n",
    "        self.label_meta = np.array([[p.label_idx, p.label_dim]], np.int32)\n",
    "        self.feat_meta = np.array([[p.feature_idx, p.feature_dim]], np.int32)\n",
    "\n",
    "    def query_training(self, graph: Graph, inputs):\n",
    "        nodes, edges, src_idx = graph_ops.sub_graph(\n",
    "            graph,\n",
    "            inputs,\n",
    "            edge_types=self.p.neighbor_edge_types,\n",
    "            num_hops=self.p.num_hops,\n",
    "            self_loop=True,\n",
    "            undirected=True,\n",
    "            return_edges=True,\n",
    "        )\n",
    "        input_mask = np.zeros(nodes.size, np.bool)\n",
    "        input_mask[src_idx] = True\n",
    "\n",
    "        feat = graph.node_features(nodes, self.feat_meta, self.p.feature_type)\n",
    "        label = graph.node_features(nodes, self.label_meta, self.p.label_type)\n",
    "        label = label.astype(np.int32)\n",
    "        edges_value = np.ones(edges.shape[0], np.float32)\n",
    "        edges = np.transpose(edges)\n",
    "        adj_shape = np.array([nodes.size, nodes.size], np.int64)\n",
    "\n",
    "        graph_tensor = (nodes, feat, input_mask, label, edges, edges_value, adj_shape)\n",
    "        return graph_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        head_num: List = [8, 1],\n",
    "        hidden_dim: int = 8,\n",
    "        num_classes: int = -1,\n",
    "        ffd_drop: float = 0.0,\n",
    "        attn_drop: float = 0.0,\n",
    "        q_param: GATQueryParameter = None,\n",
    "    ):\n",
    "        self.q = GATQuery(q_param)\n",
    "        super().__init__(FeatureType.FLOAT, 0, 0, None)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.out_dim = num_classes\n",
    "\n",
    "        self.input_layer = GATConv(\n",
    "            in_dim=in_dim,\n",
    "            attn_heads=head_num[0],\n",
    "            out_dim=hidden_dim,\n",
    "            act=F.elu,\n",
    "            in_drop=ffd_drop,\n",
    "            coef_drop=attn_drop,\n",
    "            attn_aggregate=\"concat\",\n",
    "        )\n",
    "        layer0_output_dim = head_num[0] * hidden_dim\n",
    "        assert len(head_num) == 2\n",
    "        self.out_layer = GATConv(\n",
    "            in_dim=layer0_output_dim,\n",
    "            attn_heads=head_num[1],\n",
    "            out_dim=self.out_dim,\n",
    "            act=None,\n",
    "            in_drop=ffd_drop,\n",
    "            coef_drop=attn_drop,\n",
    "            attn_aggregate=\"average\",\n",
    "        )\n",
    "\n",
    "        self.metric = Accuracy()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # fmt: off\n",
    "        nodes, feat, mask, labels, edges, edges_value, adj_shape = inputs\n",
    "        nodes = torch.squeeze(nodes)                # [N], N: num of nodes in subgraph\n",
    "        feat = torch.squeeze(feat)                  # [N, F]\n",
    "        mask = torch.squeeze(mask)                  # [N]\n",
    "        labels = torch.squeeze(labels)              # [N]\n",
    "        edges = torch.squeeze(edges)                # [X, 2], X: num of edges in subgraph\n",
    "        edges_value = torch.squeeze(edges_value)    # [X]\n",
    "        adj_shape = torch.squeeze(adj_shape)        # [2]\n",
    "        # fmt: on\n",
    "\n",
    "        sp_adj = torch.sparse_coo_tensor(edges, edges_value, adj_shape.tolist())\n",
    "        h_1 = self.input_layer(feat, sp_adj)\n",
    "        scores = self.out_layer(h_1, sp_adj)\n",
    "\n",
    "        labels = labels.type(torch.int64)\n",
    "        labels = labels[mask]  # [batch_size]\n",
    "        scores = scores[mask]  # [batch_size]\n",
    "        pred = scores.argmax(dim=1)\n",
    "        loss = self.xent(scores, labels)\n",
    "        return loss, pred, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(args: argparse.Namespace):\n",
    "    if args.seed:\n",
    "        set_seed(args.seed)\n",
    "\n",
    "    p = GATQueryParameter(\n",
    "        neighbor_edge_types=np.array([args.neighbor_edge_types], np.int32),\n",
    "        feature_idx=args.feature_idx,\n",
    "        feature_dim=args.feature_dim,\n",
    "        label_idx=args.label_idx,\n",
    "        label_dim=args.label_dim,\n",
    "    )\n",
    "\n",
    "    return GAT(\n",
    "        in_dim=args.feature_dim,\n",
    "        head_num=args.head_num,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        num_classes=args.num_classes,\n",
    "        ffd_drop=args.ffd_drop,\n",
    "        attn_drop=args.attn_drop,\n",
    "        q_param=p,\n",
    "    )\n",
    "\n",
    "def create_optimizer(args: argparse.Namespace, model: BaseModel, world_size: int):\n",
    "    return torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=args.learning_rate * world_size,\n",
    "        weight_decay=0.0005,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_args(parser):\n",
    "    parser.add_argument(\"--head_num\", type=str2list_int, default=\"8,1\", help=\"the number of attention headers.\")\n",
    "    parser.add_argument(\"--hidden_dim\", type=int, default=8, help=\"hidden layer dimension.\")\n",
    "    parser.add_argument(\"--num_classes\", type=int, default=-1, help=\"number of classes for category\")\n",
    "    parser.add_argument(\"--ffd_drop\", type=float, default=0.0, help=\"feature dropout rate.\")\n",
    "    parser.add_argument(\"--attn_drop\", type=float, default=0.0, help=\"attention layer dropout rate.\")\n",
    "    parser.add_argument(\"--l2_coef\", type=float, default=0.0005, help=\"l2 loss\")\n",
    "    parser.add_argument(\"--neighbor_edge_types\", type=str2list_int, default=\"0\", help=\"Graph Edge for attention encoder.\",)\n",
    "    parser.add_argument(\"--eval_file\", default=\"\", type=str, help=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(\n",
    "    args: argparse.Namespace,\n",
    "    model: BaseModel,\n",
    "    rank: int = 0,\n",
    "    world_size: int = 1,\n",
    "    backend: GraphEngineBackend = None,\n",
    "):\n",
    "    return TorchDeepGNNDataset(\n",
    "        sampler_class=GENodeSampler,  # FileNodeSampler,\n",
    "        node_types=np.array([0]),  # None\n",
    "        backend=backend,\n",
    "        query_fn=model.q.query_training,\n",
    "        prefetch_queue_size=2,\n",
    "        prefetch_worker_size=2,\n",
    "        sample_files=args.sample_file,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        worker_index=rank,\n",
    "        num_workers=world_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for .py file runs\n",
    "try:\n",
    "    init_args_base\n",
    "except NameError:\n",
    "    init_args_base = init_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for .py file runs\n",
    "MODEL_DIR = f\"tmp/gat_{np.random.randint(9999999)}\"\n",
    "arg_list = [\n",
    "    \"--data_dir\", \"/tmp/caveman\",\n",
    "    \"--mode\", \"train\",\n",
    "    \"--trainer\", \"base\",\n",
    "    \"--backend\", \"snark\",\n",
    "    \"--graph_type\", \"local\",\n",
    "    \"--converter\", \"skip\",\n",
    "    \"--node_type\", \"0\",\n",
    "    \"--feature_idx\", \"0\",\n",
    "    \"--feature_dim\", \"2\",\n",
    "    \"--label_idx\", \"1\",\n",
    "    \"--label_dim\", \"1\",\n",
    "    \"--num_classes\", str(num_clusters),\n",
    "    \"--batch_size\", \"10\",\n",
    "    \"--learning_rate\", \".005\",\n",
    "    \"--num_epochs\", \"10\",\n",
    "    \"--log_by_steps\", \"6\",\n",
    "    \"--use_per_step_metrics\",\n",
    "    \"--model_dir\", MODEL_DIR,\n",
    "    \"--metric_dir\", MODEL_DIR,\n",
    "    \"--save_path\", MODEL_DIR,\n",
    "]\n",
    "\n",
    "def init_args_wrap(init_args_base):\n",
    "    def init_args_new(parser):\n",
    "        init_args_base(parser)\n",
    "        parse_args = parser.parse_args\n",
    "        parser.parse_args = lambda: parse_args(arg_list)\n",
    "    return init_args_new\n",
    "\n",
    "init_args = init_args_wrap(init_args_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-02-15 09:57:47,843] {factory.py:31} INFO - GE_OMP_NUM_THREADS=1\n",
      "[2022-02-15 09:57:47,844] {factory.py:31} INFO - apex_opt_level=O2\n",
      "[2022-02-15 09:57:47,845] {factory.py:31} INFO - attn_drop=0.0\n",
      "[2022-02-15 09:57:47,846] {factory.py:31} INFO - backend=snark\n",
      "[2022-02-15 09:57:47,847] {factory.py:31} INFO - batch_size=10\n",
      "[2022-02-15 09:57:47,847] {factory.py:31} INFO - client_rank=None\n",
      "[2022-02-15 09:57:47,849] {factory.py:31} INFO - clip_grad=False\n",
      "[2022-02-15 09:57:47,850] {factory.py:31} INFO - converter=skip\n",
      "[2022-02-15 09:57:47,851] {factory.py:31} INFO - data_dir=/tmp/caveman\n",
      "[2022-02-15 09:57:47,852] {factory.py:31} INFO - data_parallel_num=2\n",
      "[2022-02-15 09:57:47,853] {factory.py:31} INFO - dim=256\n",
      "[2022-02-15 09:57:47,854] {factory.py:31} INFO - disable_ib=False\n",
      "[2022-02-15 09:57:47,855] {factory.py:31} INFO - enable_adl_uploader=False\n",
      "[2022-02-15 09:57:47,856] {factory.py:31} INFO - enable_ssl=False\n",
      "[2022-02-15 09:57:47,857] {factory.py:31} INFO - eval_during_train_by_steps=0\n",
      "[2022-02-15 09:57:47,858] {factory.py:31} INFO - eval_file=\n",
      "[2022-02-15 09:57:47,867] {factory.py:31} INFO - fanouts=[10, 10]\n",
      "[2022-02-15 09:57:47,867] {factory.py:31} INFO - featenc_config=None\n",
      "[2022-02-15 09:57:47,868] {factory.py:31} INFO - feature_dim=2\n",
      "[2022-02-15 09:57:47,869] {factory.py:31} INFO - feature_idx=0\n",
      "[2022-02-15 09:57:47,870] {factory.py:31} INFO - feature_type=float\n",
      "[2022-02-15 09:57:47,875] {factory.py:31} INFO - ffd_drop=0.0\n",
      "[2022-02-15 09:57:47,877] {factory.py:31} INFO - fp16=amp\n",
      "[2022-02-15 09:57:47,878] {factory.py:31} INFO - ge_start_timeout=30\n",
      "[2022-02-15 09:57:47,879] {factory.py:31} INFO - gpu=False\n",
      "[2022-02-15 09:57:47,881] {factory.py:31} INFO - grad_max_norm=1.0\n",
      "[2022-02-15 09:57:47,882] {factory.py:31} INFO - graph_type=local\n",
      "[2022-02-15 09:57:47,883] {factory.py:31} INFO - head_num=[8, 1]\n",
      "[2022-02-15 09:57:47,884] {factory.py:31} INFO - hidden_dim=8\n",
      "[2022-02-15 09:57:47,885] {factory.py:31} INFO - job_id=b656050f\n",
      "[2022-02-15 09:57:47,887] {factory.py:31} INFO - l2_coef=0.0005\n",
      "[2022-02-15 09:57:47,887] {factory.py:31} INFO - label_dim=1\n",
      "[2022-02-15 09:57:47,888] {factory.py:31} INFO - label_idx=1\n",
      "[2022-02-15 09:57:47,889] {factory.py:31} INFO - learning_rate=0.005\n",
      "[2022-02-15 09:57:47,890] {factory.py:31} INFO - local_rank=0\n",
      "[2022-02-15 09:57:47,891] {factory.py:31} INFO - log_by_steps=6\n",
      "[2022-02-15 09:57:47,892] {factory.py:31} INFO - max_id=None\n",
      "[2022-02-15 09:57:47,893] {factory.py:31} INFO - max_samples=0\n",
      "[2022-02-15 09:57:47,894] {factory.py:31} INFO - max_saved_ckpts=0\n",
      "[2022-02-15 09:57:47,895] {factory.py:31} INFO - meta_dir=\n",
      "[2022-02-15 09:57:47,896] {factory.py:31} INFO - metric_dir=tmp/gat_2937544\n",
      "[2022-02-15 09:57:47,896] {factory.py:31} INFO - mode=train\n",
      "[2022-02-15 09:57:47,897] {factory.py:31} INFO - model_args=\n",
      "[2022-02-15 09:57:47,898] {factory.py:31} INFO - model_dir=tmp/gat_2937544\n",
      "[2022-02-15 09:57:47,899] {factory.py:31} INFO - neighbor_count=10\n",
      "[2022-02-15 09:57:47,900] {factory.py:31} INFO - neighbor_edge_types=[0]\n",
      "[2022-02-15 09:57:47,901] {factory.py:31} INFO - node_type=0\n",
      "[2022-02-15 09:57:47,902] {factory.py:31} INFO - num_classes=5\n",
      "[2022-02-15 09:57:47,908] {factory.py:31} INFO - num_epochs=10\n",
      "[2022-02-15 09:57:47,909] {factory.py:31} INFO - num_ge=0\n",
      "[2022-02-15 09:57:47,912] {factory.py:31} INFO - num_negs=5\n",
      "[2022-02-15 09:57:47,922] {factory.py:31} INFO - num_parallel=2\n",
      "[2022-02-15 09:57:47,931] {factory.py:31} INFO - partitions=[0]\n",
      "[2022-02-15 09:57:47,932] {factory.py:31} INFO - prefetch_factor=2\n",
      "[2022-02-15 09:57:47,934] {factory.py:31} INFO - prefetch_size=16\n",
      "[2022-02-15 09:57:47,935] {factory.py:31} INFO - sample_file=\n",
      "[2022-02-15 09:57:47,936] {factory.py:31} INFO - save_ckpt_by_epochs=1\n",
      "[2022-02-15 09:57:47,937] {factory.py:31} INFO - save_ckpt_by_steps=0\n",
      "[2022-02-15 09:57:47,938] {factory.py:31} INFO - save_path=tmp/gat_2937544\n",
      "[2022-02-15 09:57:47,939] {factory.py:31} INFO - seed=None\n",
      "[2022-02-15 09:57:47,940] {factory.py:31} INFO - server_idx=None\n",
      "[2022-02-15 09:57:47,942] {factory.py:31} INFO - servers=\n",
      "[2022-02-15 09:57:47,954] {factory.py:31} INFO - skip_ge_start=False\n",
      "[2022-02-15 09:57:47,956] {factory.py:31} INFO - sort_ckpt_by_mtime=False\n",
      "[2022-02-15 09:57:47,957] {factory.py:31} INFO - ssl_cert=\n",
      "[2022-02-15 09:57:47,959] {factory.py:31} INFO - strategy=RandomWithoutReplacement\n",
      "[2022-02-15 09:57:47,964] {factory.py:31} INFO - sync_dir=\n",
      "[2022-02-15 09:57:47,973] {factory.py:31} INFO - trainer=base\n",
      "[2022-02-15 09:57:47,975] {factory.py:31} INFO - uploader_process_num=1\n",
      "[2022-02-15 09:57:47,989] {factory.py:31} INFO - uploader_store_name=\n",
      "[2022-02-15 09:57:47,992] {factory.py:31} INFO - uploader_threads_num=12\n",
      "[2022-02-15 09:57:47,993] {factory.py:31} INFO - use_per_step_metrics=True\n",
      "[2022-02-15 09:57:47,995] {factory.py:31} INFO - user_name=tiantiaw\n",
      "[2022-02-15 09:57:47,996] {factory.py:31} INFO - warmup=0.0002\n",
      "[2022-02-15 09:57:48,007] {local.py:30} INFO - Graph data path: /tmp/caveman. Partitions [0]\n",
      "[2022-02-15 09:57:48,017] {local.py:35} INFO - Loaded snark graph. Node counts: [45, 5]. Edge counts: [450]\n",
      "[2022-02-15 09:57:48,020] {base_model.py:34} INFO - [BaseModel] feature_type: FeatureType.FLOAT, feature_idx:0, feature_dim:0.\n",
      "[2022-02-15 09:57:48,035] {trainer.py:491} INFO - [1,0] Max steps per epoch:-1\n",
      "[2022-02-15 09:57:48,037] {utils.py:102} INFO - 0, input_layer.att_head-0.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:48,038] {utils.py:102} INFO - 1, input_layer.att_head-0.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:48,041] {utils.py:102} INFO - 2, input_layer.att_head-0.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,045] {utils.py:102} INFO - 3, input_layer.att_head-0.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,047] {utils.py:102} INFO - 4, input_layer.att_head-0.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,050] {utils.py:102} INFO - 5, input_layer.att_head-0.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,053] {utils.py:102} INFO - 6, input_layer.att_head-1.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:48,055] {utils.py:102} INFO - 7, input_layer.att_head-1.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:48,057] {utils.py:102} INFO - 8, input_layer.att_head-1.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,059] {utils.py:102} INFO - 9, input_layer.att_head-1.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,064] {utils.py:102} INFO - 10, input_layer.att_head-1.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,066] {utils.py:102} INFO - 11, input_layer.att_head-1.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,069] {utils.py:102} INFO - 12, input_layer.att_head-2.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:48,070] {utils.py:102} INFO - 13, input_layer.att_head-2.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:48,073] {utils.py:102} INFO - 14, input_layer.att_head-2.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,075] {utils.py:102} INFO - 15, input_layer.att_head-2.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,076] {utils.py:102} INFO - 16, input_layer.att_head-2.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,077] {utils.py:102} INFO - 17, input_layer.att_head-2.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,078] {utils.py:102} INFO - 18, input_layer.att_head-3.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:48,080] {utils.py:102} INFO - 19, input_layer.att_head-3.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:48,083] {utils.py:102} INFO - 20, input_layer.att_head-3.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,085] {utils.py:102} INFO - 21, input_layer.att_head-3.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,086] {utils.py:102} INFO - 22, input_layer.att_head-3.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,087] {utils.py:102} INFO - 23, input_layer.att_head-3.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,088] {utils.py:102} INFO - 24, input_layer.att_head-4.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:48,089] {utils.py:102} INFO - 25, input_layer.att_head-4.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:48,090] {utils.py:102} INFO - 26, input_layer.att_head-4.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,091] {utils.py:102} INFO - 27, input_layer.att_head-4.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,096] {utils.py:102} INFO - 28, input_layer.att_head-4.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,098] {utils.py:102} INFO - 29, input_layer.att_head-4.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,099] {utils.py:102} INFO - 30, input_layer.att_head-5.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:48,099] {utils.py:102} INFO - 31, input_layer.att_head-5.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:48,100] {utils.py:102} INFO - 32, input_layer.att_head-5.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,101] {utils.py:102} INFO - 33, input_layer.att_head-5.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,103] {utils.py:102} INFO - 34, input_layer.att_head-5.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,105] {utils.py:102} INFO - 35, input_layer.att_head-5.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,106] {utils.py:102} INFO - 36, input_layer.att_head-6.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:48,107] {utils.py:102} INFO - 37, input_layer.att_head-6.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:48,109] {utils.py:102} INFO - 38, input_layer.att_head-6.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,110] {utils.py:102} INFO - 39, input_layer.att_head-6.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,112] {utils.py:102} INFO - 40, input_layer.att_head-6.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,113] {utils.py:102} INFO - 41, input_layer.att_head-6.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,114] {utils.py:102} INFO - 42, input_layer.att_head-7.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:48,115] {utils.py:102} INFO - 43, input_layer.att_head-7.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:48,116] {utils.py:102} INFO - 44, input_layer.att_head-7.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,118] {utils.py:102} INFO - 45, input_layer.att_head-7.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,119] {utils.py:102} INFO - 46, input_layer.att_head-7.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:48,120] {utils.py:102} INFO - 47, input_layer.att_head-7.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,121] {utils.py:102} INFO - 48, out_layer.att_head-0.bias: torch.Size([5]), cpu\n",
      "[2022-02-15 09:57:48,122] {utils.py:102} INFO - 49, out_layer.att_head-0.w.weight: torch.Size([5, 64]), cpu\n",
      "[2022-02-15 09:57:48,123] {utils.py:102} INFO - 50, out_layer.att_head-0.attn_l.weight: torch.Size([1, 5]), cpu\n",
      "[2022-02-15 09:57:48,125] {utils.py:102} INFO - 51, out_layer.att_head-0.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,126] {utils.py:102} INFO - 52, out_layer.att_head-0.attn_r.weight: torch.Size([1, 5]), cpu\n",
      "[2022-02-15 09:57:48,126] {utils.py:102} INFO - 53, out_layer.att_head-0.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:48,127] {utils.py:110} INFO - parameter count: 673\n",
      "[2022-02-15 09:57:48,129] {logging_utils.py:76} INFO - Training worker started. Model: GAT.\n",
      "[2022-02-15 09:57:50,777] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:50,791] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:51,045] {trainer.py:245} INFO - [1,0] epoch: 0; step: 00006; loss: 1.4805; Accuracy: 0.7000; time: 3.0469s\n",
      "[2022-02-15 09:57:51,073] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-001-000000.pt.\n",
      "[2022-02-15 09:57:51,134] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:51,157] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:51,429] {trainer.py:245} INFO - [1,0] epoch: 1; step: 00006; loss: 1.2815; Accuracy: 0.6667; time: 0.3847s\n",
      "[2022-02-15 09:57:51,449] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-002-000000.pt.\n",
      "[2022-02-15 09:57:51,504] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:51,519] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:51,891] {trainer.py:245} INFO - [1,0] epoch: 2; step: 00006; loss: 1.0722; Accuracy: 0.4444; time: 0.4608s\n",
      "[2022-02-15 09:57:51,911] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-003-000000.pt.\n",
      "[2022-02-15 09:57:51,950] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:51,970] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:52,296] {trainer.py:245} INFO - [1,0] epoch: 3; step: 00006; loss: 1.0940; Accuracy: 0.6667; time: 0.4058s\n",
      "[2022-02-15 09:57:52,318] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-004-000000.pt.\n",
      "[2022-02-15 09:57:52,358] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:52,386] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:52,817] {trainer.py:245} INFO - [1,0] epoch: 4; step: 00006; loss: 0.9840; Accuracy: 0.3750; time: 0.5217s\n",
      "[2022-02-15 09:57:52,836] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-005-000000.pt.\n",
      "[2022-02-15 09:57:52,871] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:52,888] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:53,105] {trainer.py:245} INFO - [1,0] epoch: 5; step: 00006; loss: 0.8621; Accuracy: 0.8000; time: 0.2879s\n",
      "[2022-02-15 09:57:53,125] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-006-000000.pt.\n",
      "[2022-02-15 09:57:53,163] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:53,183] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:53,450] {trainer.py:245} INFO - [1,0] epoch: 6; step: 00006; loss: 0.8840; Accuracy: 0.6000; time: 0.3446s\n",
      "[2022-02-15 09:57:53,482] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-007-000000.pt.\n",
      "[2022-02-15 09:57:53,518] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:53,547] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:54,140] {trainer.py:245} INFO - [1,0] epoch: 7; step: 00006; loss: 0.8668; Accuracy: 0.5556; time: 0.6896s\n",
      "[2022-02-15 09:57:54,161] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-008-000000.pt.\n",
      "[2022-02-15 09:57:54,203] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:54,208] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:54,477] {trainer.py:245} INFO - [1,0] epoch: 8; step: 00006; loss: 0.6721; Accuracy: 0.9000; time: 0.3377s\n",
      "[2022-02-15 09:57:54,498] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-009-000000.pt.\n",
      "[2022-02-15 09:57:54,535] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:54,565] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:54,854] {trainer.py:245} INFO - [1,0] epoch: 9; step: 00006; loss: 0.7958; Accuracy: 0.6250; time: 0.3768s\n",
      "[2022-02-15 09:57:54,876] {trainer.py:454} INFO - [1,0] Saved checkpoint to tmp/gat_2937544/gnnmodel-010-000000.pt.\n",
      "[2022-02-15 09:57:54,877] {logging_utils.py:76} INFO - Training worker finished. Model: GAT.\n"
     ]
    }
   ],
   "source": [
    "run_dist(\n",
    "    init_model_fn=create_model,\n",
    "    init_dataset_fn=create_dataset,\n",
    "    init_optimizer_fn=create_optimizer,\n",
    "    init_args_fn=init_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for .py file runs\n",
    "arg_list = [\n",
    "    \"--data_dir\", \"/tmp/caveman\",\n",
    "    \"--mode\", \"evaluate\",\n",
    "    \"--trainer\", \"base\",\n",
    "    \"--backend\", \"snark\",\n",
    "    \"--graph_type\", \"local\",\n",
    "    \"--converter\", \"skip\",\n",
    "    \"--node_type\", \"0\",\n",
    "    \"--feature_idx\", \"0\",\n",
    "    \"--feature_dim\", \"2\",\n",
    "    \"--label_idx\", \"1\",\n",
    "    \"--label_dim\", \"1\",\n",
    "    \"--num_classes\", str(num_clusters),\n",
    "    \"--batch_size\", \"10\",\n",
    "    \"--learning_rate\", \".0\",\n",
    "    \"--num_epochs\", \"10\",\n",
    "    \"--log_by_steps\", \"6\",\n",
    "    \"--use_per_step_metrics\",\n",
    "    \"--model_dir\", MODEL_DIR,\n",
    "    \"--metric_dir\", MODEL_DIR,\n",
    "    \"--save_path\", MODEL_DIR,\n",
    "]\n",
    "\n",
    "def init_args_wrap(init_args_base):\n",
    "    def init_args_new(parser):\n",
    "        init_args_base(parser)\n",
    "        parse_args = parser.parse_args\n",
    "        parser.parse_args = lambda: parse_args(arg_list)\n",
    "    return init_args_new\n",
    "\n",
    "init_args = init_args_wrap(init_args_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-02-15 09:57:55,277] {factory.py:31} INFO - GE_OMP_NUM_THREADS=1\n",
      "[2022-02-15 09:57:55,278] {factory.py:31} INFO - apex_opt_level=O2\n",
      "[2022-02-15 09:57:55,279] {factory.py:31} INFO - attn_drop=0.0\n",
      "[2022-02-15 09:57:55,280] {factory.py:31} INFO - backend=snark\n",
      "[2022-02-15 09:57:55,281] {factory.py:31} INFO - batch_size=10\n",
      "[2022-02-15 09:57:55,282] {factory.py:31} INFO - client_rank=None\n",
      "[2022-02-15 09:57:55,283] {factory.py:31} INFO - clip_grad=False\n",
      "[2022-02-15 09:57:55,284] {factory.py:31} INFO - converter=skip\n",
      "[2022-02-15 09:57:55,293] {factory.py:31} INFO - data_dir=/tmp/caveman\n",
      "[2022-02-15 09:57:55,295] {factory.py:31} INFO - data_parallel_num=2\n",
      "[2022-02-15 09:57:55,297] {factory.py:31} INFO - dim=256\n",
      "[2022-02-15 09:57:55,298] {factory.py:31} INFO - disable_ib=False\n",
      "[2022-02-15 09:57:55,299] {factory.py:31} INFO - enable_adl_uploader=False\n",
      "[2022-02-15 09:57:55,300] {factory.py:31} INFO - enable_ssl=False\n",
      "[2022-02-15 09:57:55,301] {factory.py:31} INFO - eval_during_train_by_steps=0\n",
      "[2022-02-15 09:57:55,302] {factory.py:31} INFO - eval_file=\n",
      "[2022-02-15 09:57:55,307] {factory.py:31} INFO - fanouts=[10, 10]\n",
      "[2022-02-15 09:57:55,308] {factory.py:31} INFO - featenc_config=None\n",
      "[2022-02-15 09:57:55,313] {factory.py:31} INFO - feature_dim=2\n",
      "[2022-02-15 09:57:55,314] {factory.py:31} INFO - feature_idx=0\n",
      "[2022-02-15 09:57:55,316] {factory.py:31} INFO - feature_type=float\n",
      "[2022-02-15 09:57:55,320] {factory.py:31} INFO - ffd_drop=0.0\n",
      "[2022-02-15 09:57:55,321] {factory.py:31} INFO - fp16=amp\n",
      "[2022-02-15 09:57:55,322] {factory.py:31} INFO - ge_start_timeout=30\n",
      "[2022-02-15 09:57:55,324] {factory.py:31} INFO - gpu=False\n",
      "[2022-02-15 09:57:55,326] {factory.py:31} INFO - grad_max_norm=1.0\n",
      "[2022-02-15 09:57:55,327] {factory.py:31} INFO - graph_type=local\n",
      "[2022-02-15 09:57:55,328] {factory.py:31} INFO - head_num=[8, 1]\n",
      "[2022-02-15 09:57:55,330] {factory.py:31} INFO - hidden_dim=8\n",
      "[2022-02-15 09:57:55,331] {factory.py:31} INFO - job_id=a99d06d7\n",
      "[2022-02-15 09:57:55,334] {factory.py:31} INFO - l2_coef=0.0005\n",
      "[2022-02-15 09:57:55,335] {factory.py:31} INFO - label_dim=1\n",
      "[2022-02-15 09:57:55,337] {factory.py:31} INFO - label_idx=1\n",
      "[2022-02-15 09:57:55,340] {factory.py:31} INFO - learning_rate=0.0\n",
      "[2022-02-15 09:57:55,341] {factory.py:31} INFO - local_rank=0\n",
      "[2022-02-15 09:57:55,342] {factory.py:31} INFO - log_by_steps=6\n",
      "[2022-02-15 09:57:55,343] {factory.py:31} INFO - max_id=None\n",
      "[2022-02-15 09:57:55,345] {factory.py:31} INFO - max_samples=0\n",
      "[2022-02-15 09:57:55,346] {factory.py:31} INFO - max_saved_ckpts=0\n",
      "[2022-02-15 09:57:55,348] {factory.py:31} INFO - meta_dir=\n",
      "[2022-02-15 09:57:55,349] {factory.py:31} INFO - metric_dir=tmp/gat_2937544\n",
      "[2022-02-15 09:57:55,352] {factory.py:31} INFO - mode=evaluate\n",
      "[2022-02-15 09:57:55,355] {factory.py:31} INFO - model_args=\n",
      "[2022-02-15 09:57:55,357] {factory.py:31} INFO - model_dir=tmp/gat_2937544\n",
      "[2022-02-15 09:57:55,368] {factory.py:31} INFO - neighbor_count=10\n",
      "[2022-02-15 09:57:55,369] {factory.py:31} INFO - neighbor_edge_types=[0]\n",
      "[2022-02-15 09:57:55,371] {factory.py:31} INFO - node_type=0\n",
      "[2022-02-15 09:57:55,373] {factory.py:31} INFO - num_classes=5\n",
      "[2022-02-15 09:57:55,376] {factory.py:31} INFO - num_epochs=10\n",
      "[2022-02-15 09:57:55,387] {factory.py:31} INFO - num_ge=0\n",
      "[2022-02-15 09:57:55,388] {factory.py:31} INFO - num_negs=5\n",
      "[2022-02-15 09:57:55,389] {factory.py:31} INFO - num_parallel=2\n",
      "[2022-02-15 09:57:55,390] {factory.py:31} INFO - partitions=[0]\n",
      "[2022-02-15 09:57:55,391] {factory.py:31} INFO - prefetch_factor=2\n",
      "[2022-02-15 09:57:55,392] {factory.py:31} INFO - prefetch_size=16\n",
      "[2022-02-15 09:57:55,393] {factory.py:31} INFO - sample_file=\n",
      "[2022-02-15 09:57:55,395] {factory.py:31} INFO - save_ckpt_by_epochs=1\n",
      "[2022-02-15 09:57:55,396] {factory.py:31} INFO - save_ckpt_by_steps=0\n",
      "[2022-02-15 09:57:55,397] {factory.py:31} INFO - save_path=tmp/gat_2937544\n",
      "[2022-02-15 09:57:55,398] {factory.py:31} INFO - seed=None\n",
      "[2022-02-15 09:57:55,399] {factory.py:31} INFO - server_idx=None\n",
      "[2022-02-15 09:57:55,410] {factory.py:31} INFO - servers=\n",
      "[2022-02-15 09:57:55,412] {factory.py:31} INFO - skip_ge_start=False\n",
      "[2022-02-15 09:57:55,413] {factory.py:31} INFO - sort_ckpt_by_mtime=False\n",
      "[2022-02-15 09:57:55,413] {factory.py:31} INFO - ssl_cert=\n",
      "[2022-02-15 09:57:55,414] {factory.py:31} INFO - strategy=RandomWithoutReplacement\n",
      "[2022-02-15 09:57:55,415] {factory.py:31} INFO - sync_dir=\n",
      "[2022-02-15 09:57:55,416] {factory.py:31} INFO - trainer=base\n",
      "[2022-02-15 09:57:55,421] {factory.py:31} INFO - uploader_process_num=1\n",
      "[2022-02-15 09:57:55,422] {factory.py:31} INFO - uploader_store_name=\n",
      "[2022-02-15 09:57:55,428] {factory.py:31} INFO - uploader_threads_num=12\n",
      "[2022-02-15 09:57:55,433] {factory.py:31} INFO - use_per_step_metrics=True\n",
      "[2022-02-15 09:57:55,435] {factory.py:31} INFO - user_name=tiantiaw\n",
      "[2022-02-15 09:57:55,442] {factory.py:31} INFO - warmup=0.0002\n",
      "[2022-02-15 09:57:55,444] {local.py:30} INFO - Graph data path: /tmp/caveman. Partitions [0]\n",
      "[2022-02-15 09:57:55,449] {local.py:35} INFO - Loaded snark graph. Node counts: [45, 5]. Edge counts: [450]\n",
      "[2022-02-15 09:57:55,453] {base_model.py:34} INFO - [BaseModel] feature_type: FeatureType.FLOAT, feature_idx:0, feature_dim:0.\n",
      "[2022-02-15 09:57:55,465] {trainer.py:491} INFO - [1,0] Max steps per epoch:-1\n",
      "[2022-02-15 09:57:55,469] {utils.py:102} INFO - 0, input_layer.att_head-0.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:55,473] {utils.py:102} INFO - 1, input_layer.att_head-0.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:55,476] {utils.py:102} INFO - 2, input_layer.att_head-0.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,479] {utils.py:102} INFO - 3, input_layer.att_head-0.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,484] {utils.py:102} INFO - 4, input_layer.att_head-0.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,486] {utils.py:102} INFO - 5, input_layer.att_head-0.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,507] {utils.py:102} INFO - 6, input_layer.att_head-1.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:55,518] {utils.py:102} INFO - 7, input_layer.att_head-1.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:55,523] {utils.py:102} INFO - 8, input_layer.att_head-1.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,525] {utils.py:102} INFO - 9, input_layer.att_head-1.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,526] {utils.py:102} INFO - 10, input_layer.att_head-1.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,527] {utils.py:102} INFO - 11, input_layer.att_head-1.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,528] {utils.py:102} INFO - 12, input_layer.att_head-2.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:55,530] {utils.py:102} INFO - 13, input_layer.att_head-2.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:55,531] {utils.py:102} INFO - 14, input_layer.att_head-2.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,542] {utils.py:102} INFO - 15, input_layer.att_head-2.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,559] {utils.py:102} INFO - 16, input_layer.att_head-2.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,560] {utils.py:102} INFO - 17, input_layer.att_head-2.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,561] {utils.py:102} INFO - 18, input_layer.att_head-3.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:55,562] {utils.py:102} INFO - 19, input_layer.att_head-3.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:55,563] {utils.py:102} INFO - 20, input_layer.att_head-3.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,564] {utils.py:102} INFO - 21, input_layer.att_head-3.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,565] {utils.py:102} INFO - 22, input_layer.att_head-3.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,566] {utils.py:102} INFO - 23, input_layer.att_head-3.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,567] {utils.py:102} INFO - 24, input_layer.att_head-4.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:55,591] {utils.py:102} INFO - 25, input_layer.att_head-4.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:55,592] {utils.py:102} INFO - 26, input_layer.att_head-4.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,593] {utils.py:102} INFO - 27, input_layer.att_head-4.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,607] {utils.py:102} INFO - 28, input_layer.att_head-4.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,609] {utils.py:102} INFO - 29, input_layer.att_head-4.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,610] {utils.py:102} INFO - 30, input_layer.att_head-5.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:55,614] {utils.py:102} INFO - 31, input_layer.att_head-5.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:55,616] {utils.py:102} INFO - 32, input_layer.att_head-5.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,617] {utils.py:102} INFO - 33, input_layer.att_head-5.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,643] {utils.py:102} INFO - 34, input_layer.att_head-5.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,644] {utils.py:102} INFO - 35, input_layer.att_head-5.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,645] {utils.py:102} INFO - 36, input_layer.att_head-6.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:55,647] {utils.py:102} INFO - 37, input_layer.att_head-6.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:55,648] {utils.py:102} INFO - 38, input_layer.att_head-6.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,649] {utils.py:102} INFO - 39, input_layer.att_head-6.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,656] {utils.py:102} INFO - 40, input_layer.att_head-6.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,657] {utils.py:102} INFO - 41, input_layer.att_head-6.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,659] {utils.py:102} INFO - 42, input_layer.att_head-7.bias: torch.Size([8]), cpu\n",
      "[2022-02-15 09:57:55,660] {utils.py:102} INFO - 43, input_layer.att_head-7.w.weight: torch.Size([8, 2]), cpu\n",
      "[2022-02-15 09:57:55,669] {utils.py:102} INFO - 44, input_layer.att_head-7.attn_l.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,695] {utils.py:102} INFO - 45, input_layer.att_head-7.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,697] {utils.py:102} INFO - 46, input_layer.att_head-7.attn_r.weight: torch.Size([1, 8]), cpu\n",
      "[2022-02-15 09:57:55,700] {utils.py:102} INFO - 47, input_layer.att_head-7.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,702] {utils.py:102} INFO - 48, out_layer.att_head-0.bias: torch.Size([5]), cpu\n",
      "[2022-02-15 09:57:55,704] {utils.py:102} INFO - 49, out_layer.att_head-0.w.weight: torch.Size([5, 64]), cpu\n",
      "[2022-02-15 09:57:55,705] {utils.py:102} INFO - 50, out_layer.att_head-0.attn_l.weight: torch.Size([1, 5]), cpu\n",
      "[2022-02-15 09:57:55,712] {utils.py:102} INFO - 51, out_layer.att_head-0.attn_l.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,713] {utils.py:102} INFO - 52, out_layer.att_head-0.attn_r.weight: torch.Size([1, 5]), cpu\n",
      "[2022-02-15 09:57:55,714] {utils.py:102} INFO - 53, out_layer.att_head-0.attn_r.bias: torch.Size([1]), cpu\n",
      "[2022-02-15 09:57:55,719] {utils.py:110} INFO - parameter count: 673\n",
      "[2022-02-15 09:57:55,728] {trainer.py:477} INFO - [1,0] Loaded initial checkpoint: tmp/gat_2937544/gnnmodel-010-000000.pt, trained epochs: 10, steps: 0\n",
      "[2022-02-15 09:57:55,730] {logging_utils.py:76} INFO - Training worker started. Model: GAT.\n",
      "[2022-02-15 09:57:55,770] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:55,828] {samplers.py:148} INFO - Node Count ([0]): 45\n",
      "[2022-02-15 09:57:56,067] {trainer.py:358} INFO - [1,0] step: 00006; loss: 0.6658; time: 0.6228s\n",
      "[2022-02-15 09:57:56,090] {trainer.py:327} INFO - [1,0] Evaluation Accuracy: 0.8759; data size: 56;\n",
      "[2022-02-15 09:57:56,095] {logging_utils.py:76} INFO - Training worker finished. Model: GAT.\n"
     ]
    }
   ],
   "source": [
    "run_dist(\n",
    "    init_model_fn=create_model,\n",
    "    init_dataset_fn=create_dataset,\n",
    "    init_optimizer_fn=create_optimizer,\n",
    "    init_args_fn=init_args,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
