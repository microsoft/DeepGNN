{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Caveman Dataset with GAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "random.seed(0)\n",
    "num_clusters = 5\n",
    "num_nodes_in_cluster = 10\n",
    "g = nx.connected_caveman_graph(num_clusters, num_nodes_in_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "working_dir = \"/tmp/caveman\"\n",
    "try:\n",
    "    os.mkdir(working_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "test_pct = .2  # Percent of nodes in test set\n",
    "nodes = []\n",
    "data = \"\"\n",
    "for node_id in g:\n",
    "    cluster_id = float(node_id // num_nodes_in_cluster)\n",
    "    normalized_cluster = cluster_id / num_clusters - 0.4\n",
    "    node = {\n",
    "        \"node_id\": node_id,  # int\n",
    "        \"node_type\": 1 if random.random() < test_pct else 0,  # int\n",
    "        \"node_weight\": 1.,  # float\n",
    "        \"uint64_feature\": None,  # None or {\"feature id\": [\"int\", \"...\"], \"...\": \"...\"},\n",
    "        \"float_feature\": {\n",
    "            \"0\": [\n",
    "                0.02 * random.uniform(0, 1) + 2.5 * normalized_cluster - 0.01,\n",
    "                random.uniform(0, 1),\n",
    "            ],\n",
    "            \"1\": [cluster_id],\n",
    "        },  #  {\"feature id\": [\"float\", \"...\"], \"...\": \"...\"},\n",
    "        \"binary_feature\": None,  # {\"feature id\": \"string\", \"...\": \"...\"},\n",
    "        \"edge\": [\n",
    "            {\n",
    "                \"src_id\": node_id,  # int\n",
    "                \"dst_id\": neighbor_id,  # int\n",
    "                \"edge_type\": 0,  # int\n",
    "                \"weight\": 1.0,  # float\n",
    "                #     \"uint64_feature\": {\"feature id\": [\"int\", \"...\"], \"...\": [\"int\", \"...\"]},\n",
    "                #     \"float_feature\": {\"feature id\": [\"float\", \"...\"], \"...\": [\"float\", \"...\"]},\n",
    "                #     \"binary_feature\": {\"feature id\": \"string\", \"...\": \"...\"}\n",
    "            }\n",
    "            for neighbor_id in nx.neighbors(g, node_id)\n",
    "        ],\n",
    "    }\n",
    "    data += json.dumps(node) + \"\\n\"\n",
    "    nodes.append(node)\n",
    "\n",
    "data_filename = f\"{working_dir}/graph.json\"\n",
    "with open(data_filename, \"w+\") as f:\n",
    "    f.write(data)\n",
    "\n",
    "meta = '{\"node_type_num\": 2, \\\n",
    "            \"node_float_feature_num\": 2, \\\n",
    "            \"node_binary_feature_num\": 0, \\\n",
    "            \"node_uint64_feature_num\": 0, \\\n",
    "            \"edge_type_num\": 1, \\\n",
    "            \"edge_float_feature_num\": 0, \\\n",
    "            \"edge_binary_feature_num\": 0, \\\n",
    "            \"edge_uint64_feature_num\": 0}'\n",
    "\n",
    "meta_filename = f\"{working_dir}/meta.json\"\n",
    "with open(meta_filename, \"w+\") as f:\n",
    "    f.write(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepgnn.graph_engine.snark.convert as convert\n",
    "from deepgnn.graph_engine.snark.decoders import DecoderType\n",
    "partitions = 1\n",
    "convert.MultiWorkersConverter(\n",
    "    graph_path=data_filename,\n",
    "    meta_path=meta_filename,\n",
    "    partition_count=partitions,\n",
    "    output_dir=working_dir,\n",
    "    decoder_type=DecoderType.JSON,\n",
    ").convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from deepgnn.pytorch.common import Accuracy\n",
    "from deepgnn.pytorch.modeling.base_model import BaseModel\n",
    "from deepgnn.pytorch.nn.gat_conv import GATConv\n",
    "\n",
    "from deepgnn.graph_engine import Graph, FeatureType, graph_ops\n",
    "\n",
    "from deepgnn import str2list_int\n",
    "from deepgnn.pytorch.common.utils import set_seed\n",
    "from deepgnn.pytorch.common.dataset import TorchDeepGNNDataset\n",
    "from deepgnn.pytorch.modeling import BaseModel\n",
    "from deepgnn.pytorch.training import run_dist\n",
    "from deepgnn.graph_engine import GENodeSampler, FileNodeSampler, GraphEngineBackend  # Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GATQueryParameter:\n",
    "    neighbor_edge_types: np.array\n",
    "    feature_idx: int\n",
    "    feature_dim: int\n",
    "    label_idx: int\n",
    "    label_dim: int\n",
    "    feature_type: FeatureType = FeatureType.FLOAT\n",
    "    label_type: FeatureType = FeatureType.FLOAT\n",
    "    num_hops: int = 2\n",
    "\n",
    "class GATQuery:\n",
    "    def __init__(self, p: GATQueryParameter):\n",
    "        self.p = p\n",
    "        self.label_meta = np.array([[p.label_idx, p.label_dim]], np.int32)\n",
    "        self.feat_meta = np.array([[p.feature_idx, p.feature_dim]], np.int32)\n",
    "\n",
    "    def query_training(self, graph: Graph, inputs):\n",
    "        nodes, edges, src_idx = graph_ops.sub_graph(\n",
    "            graph,\n",
    "            inputs,\n",
    "            edge_types=self.p.neighbor_edge_types,\n",
    "            num_hops=self.p.num_hops,\n",
    "            self_loop=True,\n",
    "            undirected=True,\n",
    "            return_edges=True,\n",
    "        )\n",
    "        input_mask = np.zeros(nodes.size, np.bool)\n",
    "        input_mask[src_idx] = True\n",
    "\n",
    "        feat = graph.node_features(nodes, self.feat_meta, self.p.feature_type)\n",
    "        label = graph.node_features(nodes, self.label_meta, self.p.label_type)\n",
    "        label = label.astype(np.int32)\n",
    "        edges_value = np.ones(edges.shape[0], np.float32)\n",
    "        edges = np.transpose(edges)\n",
    "        adj_shape = np.array([nodes.size, nodes.size], np.int64)\n",
    "\n",
    "        graph_tensor = (nodes, feat, input_mask, label, edges, edges_value, adj_shape)\n",
    "        return graph_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        head_num: List = [8, 1],\n",
    "        hidden_dim: int = 8,\n",
    "        num_classes: int = -1,\n",
    "        ffd_drop: float = 0.0,\n",
    "        attn_drop: float = 0.0,\n",
    "        q_param: GATQueryParameter = None,\n",
    "    ):\n",
    "        self.q = GATQuery(q_param)\n",
    "        super().__init__(FeatureType.FLOAT, 0, 0, None)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.out_dim = num_classes\n",
    "\n",
    "        self.input_layer = GATConv(\n",
    "            in_dim=in_dim,\n",
    "            attn_heads=head_num[0],\n",
    "            out_dim=hidden_dim,\n",
    "            act=F.elu,\n",
    "            in_drop=ffd_drop,\n",
    "            coef_drop=attn_drop,\n",
    "            attn_aggregate=\"concat\",\n",
    "        )\n",
    "        layer0_output_dim = head_num[0] * hidden_dim\n",
    "        assert len(head_num) == 2\n",
    "        self.out_layer = GATConv(\n",
    "            in_dim=layer0_output_dim,\n",
    "            attn_heads=head_num[1],\n",
    "            out_dim=self.out_dim,\n",
    "            act=None,\n",
    "            in_drop=ffd_drop,\n",
    "            coef_drop=attn_drop,\n",
    "            attn_aggregate=\"average\",\n",
    "        )\n",
    "\n",
    "        self.metric = Accuracy()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # fmt: off\n",
    "        nodes, feat, mask, labels, edges, edges_value, adj_shape = inputs\n",
    "        nodes = torch.squeeze(nodes)                # [N], N: num of nodes in subgraph\n",
    "        feat = torch.squeeze(feat)                  # [N, F]\n",
    "        mask = torch.squeeze(mask)                  # [N]\n",
    "        labels = torch.squeeze(labels)              # [N]\n",
    "        edges = torch.squeeze(edges)                # [X, 2], X: num of edges in subgraph\n",
    "        edges_value = torch.squeeze(edges_value)    # [X]\n",
    "        adj_shape = torch.squeeze(adj_shape)        # [2]\n",
    "        # fmt: on\n",
    "\n",
    "        sp_adj = torch.sparse_coo_tensor(edges, edges_value, adj_shape.tolist())\n",
    "        h_1 = self.input_layer(feat, sp_adj)\n",
    "        scores = self.out_layer(h_1, sp_adj)\n",
    "\n",
    "        labels = labels.type(torch.int64)\n",
    "        labels = labels[mask]  # [batch_size]\n",
    "        scores = scores[mask]  # [batch_size]\n",
    "        pred = scores.argmax(dim=1)\n",
    "        loss = self.xent(scores, labels)\n",
    "        return loss, pred, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(args: argparse.Namespace):\n",
    "    if args.seed:\n",
    "        set_seed(args.seed)\n",
    "\n",
    "    p = GATQueryParameter(\n",
    "        neighbor_edge_types=np.array([args.neighbor_edge_types], np.int32),\n",
    "        feature_idx=args.feature_idx,\n",
    "        feature_dim=args.feature_dim,\n",
    "        label_idx=args.label_idx,\n",
    "        label_dim=args.label_dim,\n",
    "    )\n",
    "\n",
    "    return GAT(\n",
    "        in_dim=args.feature_dim,\n",
    "        head_num=args.head_num,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        num_classes=args.num_classes,\n",
    "        ffd_drop=args.ffd_drop,\n",
    "        attn_drop=args.attn_drop,\n",
    "        q_param=p,\n",
    "    )\n",
    "\n",
    "def create_optimizer(args: argparse.Namespace, model: BaseModel, world_size: int):\n",
    "    return torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=args.learning_rate * world_size,\n",
    "        weight_decay=0.0005,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_args(parser):\n",
    "    parser.add_argument(\"--head_num\", type=str2list_int, default=\"8,1\", help=\"the number of attention headers.\")\n",
    "    parser.add_argument(\"--hidden_dim\", type=int, default=8, help=\"hidden layer dimension.\")\n",
    "    parser.add_argument(\"--num_classes\", type=int, default=-1, help=\"number of classes for category\")\n",
    "    parser.add_argument(\"--ffd_drop\", type=float, default=0.0, help=\"feature dropout rate.\")\n",
    "    parser.add_argument(\"--attn_drop\", type=float, default=0.0, help=\"attention layer dropout rate.\")\n",
    "    parser.add_argument(\"--l2_coef\", type=float, default=0.0005, help=\"l2 loss\")\n",
    "    parser.add_argument(\"--neighbor_edge_types\", type=str2list_int, default=\"0\", help=\"Graph Edge for attention encoder.\",)\n",
    "    parser.add_argument(\"--eval_file\", default=\"\", type=str, help=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(\n",
    "    args: argparse.Namespace,\n",
    "    model: BaseModel,\n",
    "    rank: int = 0,\n",
    "    world_size: int = 1,\n",
    "    backend: GraphEngineBackend = None,\n",
    "):\n",
    "    return TorchDeepGNNDataset(\n",
    "        sampler_class=GENodeSampler,  # FileNodeSampler,\n",
    "        node_types=np.array([0]),  # None\n",
    "        backend=backend,\n",
    "        query_fn=model.q.query_training,\n",
    "        prefetch_queue_size=2,\n",
    "        prefetch_worker_size=2,\n",
    "        sample_files=args.sample_file,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        worker_index=rank,\n",
    "        num_workers=world_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for .py file runs\n",
    "try:\n",
    "    init_args_base\n",
    "except NameError:\n",
    "    init_args_base = init_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for .py file runs\n",
    "MODEL_DIR = f\"tmp/gat_{np.random.randint(9999999)}\"\n",
    "arg_list = [\n",
    "    \"--data_dir\", \"/tmp/caveman\",\n",
    "    \"--mode\", \"train\",\n",
    "    \"--trainer\", \"base\",\n",
    "    \"--backend\", \"snark\",\n",
    "    \"--graph_type\", \"local\",\n",
    "    \"--converter\", \"skip\",\n",
    "    \"--node_type\", \"0\",\n",
    "    \"--feature_idx\", \"0\",\n",
    "    \"--feature_dim\", \"2\",\n",
    "    \"--label_idx\", \"1\",\n",
    "    \"--label_dim\", \"1\",\n",
    "    \"--num_classes\", str(num_clusters),\n",
    "    \"--batch_size\", \"10\",\n",
    "    \"--learning_rate\", \".005\",\n",
    "    \"--num_epochs\", \"10\",\n",
    "    \"--log_by_steps\", \"6\",\n",
    "    \"--use_per_step_metrics\",\n",
    "    \"--model_dir\", MODEL_DIR,\n",
    "    \"--metric_dir\", MODEL_DIR,\n",
    "    \"--save_path\", MODEL_DIR,\n",
    "]\n",
    "\n",
    "def init_args_wrap(init_args_base):\n",
    "    def init_args_new(parser):\n",
    "        init_args_base(parser)\n",
    "        parse_args = parser.parse_args\n",
    "        parser.parse_args = lambda: parse_args(arg_list)\n",
    "    return init_args_new\n",
    "\n",
    "init_args = init_args_wrap(init_args_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dist(\n",
    "    init_model_fn=create_model,\n",
    "    init_dataset_fn=create_dataset,\n",
    "    init_optimizer_fn=create_optimizer,\n",
    "    init_args_fn=init_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for .py file runs\n",
    "arg_list = [\n",
    "    \"--data_dir\", \"/tmp/caveman\",\n",
    "    \"--mode\", \"evaluate\",\n",
    "    \"--trainer\", \"base\",\n",
    "    \"--backend\", \"snark\",\n",
    "    \"--graph_type\", \"local\",\n",
    "    \"--converter\", \"skip\",\n",
    "    \"--node_type\", \"0\",\n",
    "    \"--feature_idx\", \"0\",\n",
    "    \"--feature_dim\", \"2\",\n",
    "    \"--label_idx\", \"1\",\n",
    "    \"--label_dim\", \"1\",\n",
    "    \"--num_classes\", str(num_clusters),\n",
    "    \"--batch_size\", \"10\",\n",
    "    \"--learning_rate\", \".0\",\n",
    "    \"--num_epochs\", \"10\",\n",
    "    \"--log_by_steps\", \"6\",\n",
    "    \"--use_per_step_metrics\",\n",
    "    \"--model_dir\", MODEL_DIR,\n",
    "    \"--metric_dir\", MODEL_DIR,\n",
    "    \"--save_path\", MODEL_DIR,\n",
    "]\n",
    "\n",
    "def init_args_wrap(init_args_base):\n",
    "    def init_args_new(parser):\n",
    "        init_args_base(parser)\n",
    "        parse_args = parser.parse_args\n",
    "        parser.parse_args = lambda: parse_args(arg_list)\n",
    "    return init_args_new\n",
    "\n",
    "init_args = init_args_wrap(init_args_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dist(\n",
    "    init_model_fn=create_model,\n",
    "    init_dataset_fn=create_dataset,\n",
    "    init_optimizer_fn=create_optimizer,\n",
    "    init_args_fn=init_args,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
